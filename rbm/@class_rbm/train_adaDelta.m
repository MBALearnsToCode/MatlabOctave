function [rbm_updated ...
   trainGoodnessAvg_exclWeightPenalty_approx ...
   validGoodnessAvg_exclWeightPenalty ...   
   trainGoodnesssAvg_exclWeightPenalty_approx ...
   validGoodnesssAvg_exclWeightPenalty ...   
   immedWeightChangesMemory_updated ...
   avgWeightChangesSq_updated ...
   immedWeightGradsMemory_updated ...
   avgWeightGradsSq_updated] = ...
   train_adaDelta(rbm, dataArgs_list, ...   
   trainNumEpochs = 1, cd_chainLengths = 1, ...
   trainBatchSize = false, trainRandShuff = true, ...
   trainGoodnessApproxChunk_numBatches = 1, ...
   validGoodnessCalcInterval_numChunks = 1, ...
   stepRate_init = 1, decayRate_init = 9e-1, ...
   momentumRate_init = 0, nesterovAccGrad = true, ...
   offsetTerm = 1e-6, weightRegulArgs_list = {{'L2'} [0]}, ...
   bestStop = true, ...
   immedWeightChangesMemory_init = {}, ...
   avgWeightChangesSq_init = {}, ...
   immedWeightGradsMemory_init = {}, ...
   avgWeightGradsSq_init = {}, ...
   plotLearningCurves = true, batchDim = 3, ...
   saveEvery_numMins = 3, saveFileName = 'rbm_trained.mat', ...
   useRandSource = false, randSource_Mat = [])
   % zzzBORED = 'Z' - waiting for Octave's TIMER functionality
   
   rbm_updated = rbm;
   numTransforms = rbm_updated.numTransforms;
   weightDimSizes = rbm.weightDimSizes;
   numTargets = columns(weightDimSizes{numTransforms});
   GoodnessFuncType = rbm.GoodnessFuncType;
   GoodnessFuncType_isCrossEntropy = ...
      strcmp(GoodnessFuncType, 'CE-L') || ...
      strcmp(GoodnessFuncType, 'CE-S');
   
   zeros_rbm_weightDimSizes = ...
      zeros_weightDimSizes(rbm_updated);
   
   if isempty(rbm_immedWeightChangesMemory_init)
      rbm_immedWeightChangesMemory_updated = ...         
         zeros_rbm_weightDimSizes;
   else
      rbm_immedWeightChangesMemory_updated = ...
         rbm_immedWeightChangesMemory_init;      
   endif
   
   if isempty(rbm_avgWeightChangesSq_init)
      rbm_avgWeightChangesSq_updated = ...
         zeros_rbm_weightDimSizes;
      rbm_avgWeightChangesSq_startAtZero...
         (1 : numTransforms) = true;
   else
      rbm_avgWeightChangesSq_updated = ...
         rbm_avgWeightChangesSq_init;
      rbm_avgWeightChangesSq_startAtZero...
         (1 : numTransforms) = false;
   endif
   
   if isempty(rbm_immedWeightGradsMemory_init)
      rbm_immedWeightGradsMemory_updated = ...
         zeros_rbm_weightDimSizes;
   else
      rbm_immedWeightGradsMemory_updated = ...
         rbm_immedWeightGradsMemory_init;
   endif
   
   if isempty(rbm_avgWeightGradsSq_init)
      rbm_avgWeightGradsSq_updated = ...
         zeros_rbm_weightDimSizes;
      rbm_avgWeightGradsSq_startAtZero...
         (1 : numTransforms) = true;
   else
      rbm_avgWeightGradsSq_updated = ...
         rbm_avgWeightGradsSq_init;
      rbm_avgWeightGradsSq_startAtZero...
         (1 : numTransforms) = false;
   endif   
   
   trainGoodnessAvg_exclWeightPenalty_approx = ...
      validGoodnessAvg_exclWeightPenalty = ...
      testGoodnessAvg_exclWeightPenalty = 0;
   trainAccuracyAvg_text = validAccuracyAvg_text = '';
   trainGoodnesssAvg_exclWeightPenalty_approx = ...
      validGoodnesssAvg_exclWeightPenalty = [];
   
   % following section needs trimming down later on   
   setData = setTrainValidTestData(dataArgs_list, ...
      trainBatchSize, trainRandShuff);
   batchSize = setData.trainBatchSize;
   trainNumBatches = setData.trainNumBatches;
   trainBatchDim = setData.trainBatchDim;
   trainInput = setData.trainInput;
   trainInput_batches = setData.trainInput_batches;
   validInput = setData.validInput;

   valid_provided = ~(isempty(validInput) ...
      || isempty(validTargetOutput));
   validProvided_n_bestStop = valid_provided && bestStop;
   if (valid_provided)
      validBatchDim = max(arrNumDims(validInput), ...
         arrNumDims(validTargetOutput));
   endif
   if (validProvided_n_bestStop)
      rbm_best = rbm_updated;
      validGoodnessAvg_exclWeightPenalty_best = Inf;
      toSaveBest = false;
   endif 
   
   test_provided = ~(isempty(testInput) ...
      || isempty(testTargetOutput));
   if (test_provided)
      testBatchDim = max(arrNumDims(testInput), ...
         arrNumDims(testTargetOutput));
   endif
   
   stepRate = stepRate_init;
   decayRate = decayRate_init;
   momentumRate = momentumRate_init;
       
   trainGoodnessAvg_exclWeightPenalty_currChunk = ...
      trainAccuracyAvg_currChunk = ...
      chunk = chunk_inEpoch = batch_inChunk = 0;
   
   validGoodnessCalcInterval_numBatches = ...
      validGoodnessCalcInterval_numChunks ...
      * trainGoodnessApproxChunk_numBatches;
   
   saveFileName = upper(saveFileName); 
    
   overview(rbm_updated);
fprintf('\n\nTRAIN FORWARD-FEEDING NEURAL NETWORK (METHOD: ADADELTA):\n\n');
   fprintf('   DATA SETS:\n');
   fprintf('      Training: %i cases\n', ...
      size(trainTargetOutput, 1));
   if (valid_provided)
      fprintf('      Validation: %i cases\n', ...
         rows(validTargetOutput));      
   endif
   if (test_provided)
      fprintf('      Test: %i cases\n', ...
         rows(testTargetOutput));
   endif
   
   fprintf('\n   TRAINING SETTINGS:\n');
   fprintf('      Training Epochs: %i\n', trainNumEpochs); 
fprintf('      Training Batches per Epoch: %i batches of %i', ...
      trainNumBatches, batchSize);
   if (trainRandShuff)
      fprintf(', shuffled in each epoch\n')
   else
      fprintf('\n');
   endif
   fprintf('      Step Rate: %g\n', stepRate);
   fprintf('      RMS Decay Rate: %g\n', decayRate);   
   if (momentumRate)
      fprintf('      Momentum: %g', momentumRate);
      if (nesterovAccGrad)
         fprintf(',   applying Nesterov Accelerated Gradient (NAG)\n');
      else
         fprintf('\n');
      endif
   endif

   fprintf('      Weight Penalty Methods & Parameters:\n');
   weightRegulFuncs = weightRegulArgs_list{1};
   weightRegulParams = weightRegulArgs_list{2};
   for (l = 1 : numTransforms)
      if (l > 1)
         if (length(weightRegulFuncs) < l)
            weightRegulFuncs{l} = weightRegulFuncs{l - 1};
         endif        
         if (length(weightRegulParams) < l)
            weightRegulParams(l) = weightRegulParams(l - 1);
         endif
      endif      
      if strcmp(weightRegulFuncs{l}, ...
         const_MacKay_empBayes_str)         
         weightRegulParam_print = '';
      else
         weightRegulParam_print = ...
            sprintf(': penalty term = %g', ...
            weightRegulParams(l));
      endif      
      fprintf(cstrcat('         Layer #', sprintf('%i', l),': ', ...
         weightRegulFuncs{l}, weightRegulParam_print, '\n'));         
   endfor
   
   if (bestStop)
fprintf('      Model Selection by Best Validation Performance\n');
   endif
   fprintf('      Saving Results in %s on Working Directory every %i Minutes\n', ...
      saveFileName, saveEvery_numMins);
   fprintf('\n');
   fprintf('   TRAINING PROGRESS:\n');
% fprintf(cstrcat('      (pre-terminate by "', zzzBORED, '" key stroke)\n'));
fprintf('      Training Avg Goodness (excl Weight Penalty) approx''d w/ each chunk of %i batches\n',
      trainGoodnessApproxChunk_numBatches);
fprintf('      Validation Avg Goodness (excl Weight Penalty) updated every %i batches\n', ...
      validGoodnessCalcInterval_numBatches);
   if (GoodnessFuncType_isCrossEntropy)
fprintf('         (Est Avg Classification Accuracy %%s in brackets)\n');
   endif
   lastSaveTime = trainStartTime = time;
   
   for (epoch = 1 : trainNumEpochs)
      
      if (trainRandShuff) && (epoch > 1)
         train_reshuffled = setTrainValidTestData...
            ({trainInput trainTargetOutput 1.0}, ...
            batchSize, trainRandShuff);
         trainInput_batches = ...
            train_reshuffled.trainInput_batches;
         trainTargetOutput_batches = ...
            train_reshuffled.trainTargetOutput_batches;    
      endif
      
      for (batch = 1 : trainNumBatches)
         
         if (trainNumBatches > 1)
            trainInput_batch = arrSubsetHighestDim...
              (trainInput_batches, batch);
            trainTargetOutput_batch = ...
               arrSubsetHighestDim...
               (trainTargetOutput_batches, batch);
         else
            trainInput_batch = trainInput_batches;
            trainTargetOutput_batch = ...
               trainTargetOutput_batches;
         endif
           
         if (momentumRate)
   
            if (nesterovAccGrad)
                                             
               [trainGoodnessAvg_exclWeightPenalty_currBatch ...
                  trainAccuracyAvg_currBatch] = ...
                  GoodnessAvg_exclWeightPenalty(rbm_updated, ...
                  trainInput_batch, ...
                  trainTargetOutput_batch, ...
         targetOutputs_areClassIndcsColVecs_ofNumClasses, ...
                  trainBatchDim);
                  
               rbm_temp = rbm_updated;
               for (l = 1 : numTransforms)
                  w = rbm_temp.weights{l};
                  rbm_temp.weights{l} = w + momentumRate ...
                  * rbm_immedWeightChangesMemory_updated{l};                  
               endfor               
               [weightGrads_temp, ~, ~, ~, ~, ~, ...
                  weightRegulParams] = fProp_bProp...
                  (rbm_temp, trainInput_batch, ...
                  trainTargetOutput_batch, ...
         targetOutputs_areClassIndcsColVecs_ofNumClasses, ...
                  {weightRegulFuncs weightRegulParams});               
               
               for (l = 1 : numTransforms)
                  
                  %if (rbm_avgWeightGradsSq_startAtZero(l))
                  %   rbm_avgWeightGradsSq_updated{l} = ...
                  %      weightGrads_temp{l} .^ 2;
                  %   rbm_avgWeightGradsSq_startAtZero(l) = ...
                  %      false;
                  %else
                     rbm_avgWeightGradsSq_updated{l} = ...
                        decayRate ...
                        * rbm_avgWeightGradsSq_updated{l} ...
                        + (1 - decayRate) ...
                        * (weightGrads_temp{l} .^ 2);
                  %endif
               
                  stepRates_adapt{l} = ...
                  sqrt(rbm_avgWeightChangesSq_updated{l} ...
                     + offsetTerm) ...
                  ./ sqrt(rbm_avgWeightGradsSq_updated{l} ...
                     + offsetTerm);
               
               rbm_immedWeightChangesMemory_updated{l} = ...
                     - stepRate * (stepRates_adapt{l} ...
                     .* weightGrads_temp{l});
                     
                  w = rbm_updated.weights{l};
                  rbm_updated.weights{l} = w ...
                  + rbm_immedWeightChangesMemory_updated{l};   
            
                  %if (rbm_avgWeightChangesSq_startAtZero(l))
                  %   rbm_avgWeightChangesSq_updated{l} = ...
               %rbm_immedWeightChangesMemory_updated{l} .^ 2;
                  %rbm_avgWeightChangesSq_startAtZero(l) = ...
                  %      false;
                  %else
                     rbm_avgWeightChangesSq_updated{l} = ...
                        decayRate ...
                     * rbm_avgWeightChangesSq_updated{l} ...
                        + (1 - decayRate) ...
               * rbm_immedWeightChangesMemory_updated{l} .^ 2;
                  %endif
                  
               endfor    
   
            else
                  
               [weightGrads, ...
               trainGoodnessAvg_exclWeightPenalty_currBatch, ...
                  ~, ~, trainAccuracyAvg_currBatch, ~, ...
                  weightRegulParams] = fProp_bProp...
                  (rbm_updated, trainInput_batch, ...
                  trainTargetOutput_batch, ...
         targetOutputs_areClassIndcsColVecs_ofNumClasses, ...
                  {weightRegulFuncs weightRegulParams});

               for (l = 1 : numTransforms)
               
                  %if (rbm_avgWeightGradsSq_startAtZero(l))
                  %   rbm_avgWeightGradsSq_updated{l} = ...
                  %      weightGrads{l} .^ 2;
                  %   rbm_avgWeightGradsSq_startAtZero(l) = ...
                  %      false;
                  %else               
                     rbm_avgWeightGradsSq_updated{l} = ...
                        decayRate ...
                        * rbm_avgWeightGradsSq_updated{l} ...
                        + (1 - decayRate) ...
                        * (weightGrads{l} .^ 2);
                  %endif
                  
                  stepRates_adapt{l} = ...
                  sqrt(rbm_avgWeightChangesSq_updated{l} ...
                     + offsetTerm) ...
                  ./ sqrt(rbm_avgWeightGradsSq_updated{l} ...
                     + offsetTerm);
                  
               rbm_immedWeightChangesMemory_updated{l} = ...                   
                     momentumRate ...
               * rbm_immedWeightChangesMemory_updated{l} ...
                     - stepRate * (stepRates_adapt{l} ...
                     .* weightGrads{l});
                                    
                  w = rbm_updated.weights{l};
                  rbm_updated.weights{l} = w ...
                  + rbm_immedWeightChangesMemory_updated{l};
                  
                  %if (rbm_avgWeightChangesSq_startAtZero(l))
                  %   rbm_avgWeightChangesSq_updated{l} = ...
               %rbm_immedWeightChangesMemory_updated{l} .^ 2;
                  %rbm_avgWeightChangesSq_startAtZero(l) = ...
                  %      false;
                  %else
                     rbm_avgWeightChangesSq_updated{l} = ...
                        decayRate ...
                     * rbm_avgWeightChangesSq_updated{l} ...
                        + (1 - decayRate) ...
               * rbm_immedWeightChangesMemory_updated{l} .^ 2;
                  %endif
                  
               endfor
         
            endif
      
         else 
      
            [weightGrads, ...
               trainGoodnessAvg_exclWeightPenalty_currBatch, ...
               ~, ~, trainAccuracyAvg_currBatch, ~, ...
               weightRegulParams] = fProp_bProp...
               (rbm_updated, trainInput_batch, ...
               trainTargetOutput_batch, ...
            targetOutputs_areClassIndcsColVecs_ofNumClasses, ...               
               {weightRegulFuncs weightRegulParams});           
                        
            for (l = 1 : numTransforms)
            
               %if (rbm_avgWeightGradsSq_startAtZero(l))
               %   rbm_avgWeightGradsSq_updated{l} = ...
               %      weightGrads{l} .^ 2;
               %   rbm_avgWeightGradsSq_startAtZero(l) = ...
               %      false;
               %else
                  rbm_avgWeightGradsSq_updated{l} = ...
                     decayRate ...
                     * rbm_avgWeightGradsSq_updated{l} ...
                     + (1 - decayRate) ...
                     * (weightGrads{l} .^ 2);
               %endif
               
               stepRates_adapt{l} = ...
                  sqrt(rbm_avgWeightChangesSq_updated{l} ...
                  + offsetTerm) ...
                  ./ sqrt(rbm_avgWeightGradsSq_updated{l} ...
                  + offsetTerm);
               
               rbm_immedWeightChangesMemory_updated{l} = ...
                  - stepRate * (stepRates_adapt{l} ...
                  .* weightGrads{l});
                  
               w = rbm_updated.weights{l};
               rbm_updated.weights{l} = w ...
                  + rbm_immedWeightChangesMemory_updated{l};
               
               %if (rbm_avgWeightChangesSq_startAtZero(l))
               %   rbm_avgWeightChangesSq_updated{l} = ...
               %rbm_immedWeightChangesMemory_updated{l} .^ 2;
               %   rbm_avgWeightChangesSq_startAtZero(l) = ...
               %         false;
               %else
                  rbm_avgWeightChangesSq_updated{l} = ...
                     decayRate ...
                     * rbm_avgWeightChangesSq_updated{l} ...
                     + (1 - decayRate) ...
               * rbm_immedWeightChangesMemory_updated{l} .^ 2;
               %endif   
            
            endfor
            
         endif
         
         batch_inChunk++;         
         trainGoodnessAvg_exclWeightPenalty_currChunk += ...
            (trainGoodnessAvg_exclWeightPenalty_currBatch ...
            - trainGoodnessAvg_exclWeightPenalty_currChunk) ...
            / batch_inChunk;
         trainAccuracyAvg_currChunk += ...
            (trainAccuracyAvg_currBatch ...
            - trainAccuracyAvg_currChunk) ...
            / batch_inChunk;
         if (GoodnessFuncType_isCrossEntropy)
            trainAccuracyAvg_text = sprintf...
               (' (%.3g%%)', 100 * ...
               trainAccuracyAvg_currChunk);
         endif
         
         if (batch_inChunk == ...
            trainGoodnessApproxChunk_numBatches) || ...
            (batch == trainNumBatches)
                        
            chunk_inEpoch++; chunk++;
         trainGoodnesssAvg_exclWeightPenalty_approx(chunk) = ...
               trainGoodnessAvg_exclWeightPenalty_currChunk;
               
            if (valid_provided && ((mod(batch, ...
               validGoodnessCalcInterval_numBatches) == 0) || ...
               (batch == trainNumBatches)))
            
               [GoodnessAvg_valid validAccuracyAvg] = ...
                  GoodnessAvg_exclWeightPenalty(rbm_updated, ...
                  validInput, validTargetOutput, ...
         targetOutputs_areClassIndcsColVecs_ofNumClasses, ...
                  validBatchDim);
               validGoodnessAvg_exclWeightPenalty = ...
                  validGoodnesssAvg_exclWeightPenalty(chunk) = ...
                  GoodnessAvg_valid;
               if (GoodnessFuncType_isCrossEntropy)
                  validAccuracyAvg_text = sprintf...
                     (' (%.3g%%)', 100 * validAccuracyAvg);
               endif               
               if (bestStop && ...
                  (validGoodnessAvg_exclWeightPenalty ...
                  < validGoodnessAvg_exclWeightPenalty_best))
                  rbm_best = rbm_updated;
                  validGoodnessAvg_exclWeightPenalty_best = ...
                     validGoodnessAvg_exclWeightPenalty;
                  validAccuracyAvg_best = validAccuracyAvg;
                  toSaveBest = true;
               endif
            
            else
            
               validGoodnesssAvg_exclWeightPenalty(chunk) = NA;            
            
            endif
            
            if (time > lastSaveTime + saveEvery_numMins * 60)
               if (validProvided_n_bestStop)
                  if (toSaveBest)
                     saveFile(rbm_updated, saveFileName);
                     lastSaveTime = time;                  
                     toSaveBest = false;
                  endif
               else
                  saveFile(rbm_updated, saveFileName);
                  lastSaveTime = time;
               endif
               
            endif            
            
            trainCurrTime = time;
            trainElapsedTime_numMins = ...
               (trainCurrTime - trainStartTime) / 60;
fprintf('\r      Epoch %i Batch %i: TRAIN %.3g%s, VALID %.3g%s, elapsed %.3gm      ', ...
               epoch, batch, ...
               trainGoodnessAvg_exclWeightPenalty_currChunk, ...
               trainAccuracyAvg_text, ...
               validGoodnessAvg_exclWeightPenalty, ...
               validAccuracyAvg_text, trainElapsedTime_numMins);
            
            if (plotLearningCurves)
               plotLearningCurves_rbm...
                  (trainGoodnessAvg_exclWeightPenalty_currChunk, ...
                  trainAccuracyAvg_text, ...
                  trainGoodnesssAvg_exclWeightPenalty_approx, ...   
                  validGoodnessAvg_exclWeightPenalty, ...
                  validAccuracyAvg_text, ...
                  validGoodnesssAvg_exclWeightPenalty, ...  
                  chunk, trainGoodnessApproxChunk_numBatches, ...
                  batchSize, trainElapsedTime_numMins);
            endif
               
            trainGoodnessAvg_exclWeightPenalty_currChunk = ...
               trainAccuracyAvg_currChunk = batch_inChunk = 0;  
 
            if (batch == trainNumBatches)         
               chunk_inEpoch = 0;
            endif
 
         endif
         
      endfor
   
   endfor

fprintf('\n\n   RESULTS:   Training Finished w/ Following Avg Goodnesss (excl Weight Penalty):\n');

   trainGoodnessAvg_exclWeightPenalty_approx = ...
      trainGoodnesssAvg_exclWeightPenalty_approx(end);
   fprintf('      Training (approx''d by last chunk): %.3g%s\n', ...
      trainGoodnessAvg_exclWeightPenalty_approx, ...
      trainAccuracyAvg_text);
      
   if (valid_provided)
      if (bestStop)
         rbm_updated = rbm_best;
         validGoodnessAvg_exclWeightPenalty = ...
            validGoodnessAvg_exclWeightPenalty_best;
         validAccuracyAvg = validAccuracyAvg_best;
         if (GoodnessFuncType_isCrossEntropy)
            validAccuracyAvg_text = sprintf...
               (' (%.3g%%)', 100 * validAccuracyAvg);
         endif
      endif
      fprintf('      Validation: %.3g%s\n', ...
         validGoodnessAvg_exclWeightPenalty, ...
         validAccuracyAvg_text);
   endif   
   
   if (test_provided)
      [testGoodnessAvg_exclWeightPenalty testAccuracyAvg] = ...
         GoodnessAvg_exclWeightPenalty(rbm_updated, ...
         testInput, testTargetOutput, ...
         targetOutputs_areClassIndcsColVecs_ofNumClasses, ...
         testBatchDim);
      if (GoodnessFuncType_isCrossEntropy)
         testAccuracyAvg_text = sprintf...
            (' (%.3g%%)', 100 * testAccuracyAvg);
      else
         testAccuracyAvg_text = '';
      endif
      fprintf('      Test: %.3g%s\n', ...
         testGoodnessAvg_exclWeightPenalty, ...
         testAccuracyAvg_text);
   endif  

   fprintf('\n');
   
   saveFile(rbm_updated, saveFileName);
   
endfunction