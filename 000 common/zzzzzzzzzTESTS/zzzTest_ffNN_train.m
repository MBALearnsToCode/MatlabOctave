function ffNN = zzzTest_ffNN_train(method = 'conjGrad')   
   
   % load data
   [trainInput trainTargetOutput trainTargetOutput_labels ...
      validInput validTargetOutput validTargetOutput_labels ...
      testInput testTargetOutput testTargetOutput_labels] = ...
      load_mNIST_11k;
   % reshape data to fit model's architecture
   trainInput = trainInput(:, :);
   validInput = validInput(:, :);
   testInput = testInput(:, :);
   % number of cases
   trainNumCases = length(trainTargetOutput_labels);
   validNumCases = length(validTargetOutput_labels);
   testNumCases = length(testTargetOutput_labels);
  
   % create FFNN
   ffNN = class_ffNN...
      (inputDimSizes_perCase = 256, ...
      addlLayersNumsNodes = [30 10], ...
      transformFuncs = {}, ...
      displayOverview = false, ...
      initWeights_rand = true);
   
   % function handles for different methods
   switch (method)
      
      case ('conjGrad')
         train = @(data, ...
            numEpochs = 100, ...
            batchSize = false, ...
            weightRegulParam = 0, ...
            bestStop = true, ...
            fileName = 'ffNN_trained.mat') ...
            train_conjGrad...
            (ffNN_init = ffNN, ...
            dataArgs = data, ...
            targetOutput_isClassIndcsColVec = false, ...
            numIters_perBatch = 3, ...
            trainNumEpochs = numEpochs, ...
            trainBatchSize = batchSize, ...
            trainRandShuff = (batchSize > 0), ...
            trainCostApproxChunk_numBatches = 3, ...
            validCostCalcInterval_numChunks = 3, ...
            weightRegulArgs = {{'L2'} [weightRegulParam]}, ...
            connectProbs = [1.0], ...
            bestStop = bestStop, ...
            saveFileName = fileName);
   
      case ('conjGrad')
         train = @(data, ...
            numEpochs = 100, ...
            batchSize = false, ...
            weightRegulParam = 0, ...
            bestStop = true, ...
            fileName = 'ffNN_trained.mat') ...
            train_conjGrad...
            (ffNN_init = ffNN, ...
            dataArgs = data, ...
            targetOutput_isClassIndcsColVec = false, ...
            numIters_perBatch = 3, ...
            trainNumEpochs = numEpochs, ...
            trainBatchSize = batchSize, ...
            trainRandShuff = (batchSize > 0), ...
            trainCostApproxChunk_numBatches = 3, ...
            validCostCalcInterval_numChunks = 3, ...
            weightRegulArgs = {{'L2'} [weightRegulParam]}, ...
            connectProbs = [1.0], ...
            bestStop = bestStop, ...
            saveFileName = fileName); 
     
      case ('gradDesc')
         train = @(data, ...
            numEpochs = 100, ...
            batchSize = false, ...
            weightRegulParam = 0, ...
            bestStop = true, ...
            fileName = 'ffNN_trained.mat') ...
            train_gradDesc...
            (ffNN_init = ffNN, ...
            dataArgs = data, ...
            targetOutput_isClassIndcsColVec = false, ...
            trainNumEpochs = numEpochs, ...
            trainBatchSize = batchSize, ...   
            trainRandShuff = (batchSize > 0), ...
            trainCostApproxChunk_numBatches = 3, ...
            validCostCalcInterval_numChunks = 3, ...
            learningRate_init = 3e-1, ...
            momentumRate_init = 9e-1, ...
            nesterovAccGrad = true, ...
            weightRegulArgs = {{'L2'} [weightRegulParam]}, ...
            connectProbs = [1.0], ...
            bestStop = bestStop, ...
            saveFileName = fileName);
    
      case ('rmsProp')
         train = @(data, ...
            numEpochs = 100, ...
            batchSize = false, ...
            weightRegulParam = 0, ...
            bestStop = true, ...
            fileName = 'ffNN_trained.mat') ...
            train_rmsProp...
            (ffNN_init = ffNN, ...
            dataArgs = data, ...
            targetOutput_isClassIndcsColVec = false, ...
            trainNumEpochs = numEpochs, ...
            trainBatchSize = batchSize, ...
            trainRandShuff = (batchSize > 0), ...
            trainCostApproxChunk_numBatches = 3, ...
            validCostCalcInterval_numChunks = 3, ...
            stepRate_init = 3e-1, ...
            decayRate_init = 9e-1, ...
            momentumRate_init = 9e-1, ...
            nesterovAccGrad = true, ...
            weightRegulArgs = {{'L2'} [weightRegulParam]}, ...
            connectProbs = [1.0], ...
            bestStop = true, ...
            saveFileName = fileName);
            
      case ('adaDelta')
         train = @(data, ...
            numEpochs = 100, ...
            batchSize = false, ...
            weightRegulParam = 0, ...
            bestStop = true, ...
            fileName = 'ffNN_trained.mat') ...
            train_adaDelta...
            (ffNN_init = ffNN, ...
            dataArgs = data, ...
            targetOutput_isClassIndcsColVec = false, ...
            trainNumEpochs = numEpochs, ...
            trainBatchSize = batchSize, ...
            trainRandShuff = (batchSize > 0), ...
            trainCostApproxChunk_numBatches = 3, ...
            validCostCalcInterval_numChunks = 3, ...
            stepRate_init = 1, ...
            decayRate_init = 9e-1, ...
            momentumRate_init = 0, ...
            nesterovAccGrad = true, ...
            offsetTerm = 1e-4, ...
            weightRegulArgs = {{'L2'} [weightRegulParam]}, ...
            connectProbs = [1.0], ...
            bestStop = true, ...
            saveFileName = fileName);
            
   endswitch
   
   fprintf('\nSCENARIO: train FFNN with only Training data\n');
   fprintf('TO TEST: final Training set cost & confidence match last iteration\n');
   fprintf('TO TEST: Training set cost, confidence & accuracy are correct\n\n');
   pausePressKey;
   close all;
   train(data = {trainInput trainTargetOutput}, ...
      numEpochs = 23, ...
      batchSize = false, ...
      weightRegulParam = 0, ...
      bestStop = true);
   fprintf('MANUAL CROSS-CHECKS:\n');   
   ffNN = ffNN_loadFile('ffNN_trained.mat');
   [~, ~, ~, hypoOutput] = fProp_bProp(ffNN, trainInput);
   calcs = costFuncAvg_crossEntropy_softmax...
      (hypoOutput, trainTargetOutput);
   trainCost = sprintf('%.3g', calcs.val)
   trainConfidence = sprintf('%.3g%%', ...
      100 * sum(sum(hypoOutput .* trainTargetOutput)) ...
      / trainNumCases)
   pred = predict(ffNN, trainInput);
   trainAccuracy = sprintf('%.3g%%', ...
      100 * mean(double(pred == trainTargetOutput_labels)))   
   fprintf('\n');
   
   
   
   fprintf('\nSCENARIO: train FFNN with Training & Validation data, WITHOUT early stop\n');
   fprintf('TO TEST: Validation reporting every 3 chunks & at last iteration\n');
   fprintf('TO TEST: no Best Validation reporting\n');
   fprintf('TO TEST: final Training & Validation set costs & confidences match last iteration\n');
   fprintf('TO TEST: Training & Validation set costs, confidences & accuracies are correct\n\n');
   pausePressKey;
   close all;
   train(dataArgs = {trainInput trainTargetOutput ...
                     validInput validTargetOutput}, ...
      numEpochs = 100, ...
      batchSize = false, ...
      weightRegulParam = 0, ...
      bestStop = false);
   fprintf('MANUAL CROSS-CHECKS:\n');   
   ffNN = ffNN_loadFile('ffNN_trained.mat');
   [~, ~, ~, hypoOutput] = fProp_bProp(ffNN, trainInput);
   calcs = costFuncAvg_crossEntropy_softmax...
      (hypoOutput, trainTargetOutput);
   trainCost = sprintf('%.3g', calcs.val)
   trainConfidence = sprintf('%.3g%%', ...
      100 * sum(sum(hypoOutput .* trainTargetOutput)) ...
      / trainNumCases)
   pred = predict(ffNN, trainInput);
   trainAccuracy = sprintf('%.3g%%', ...
      100 * mean(double(pred == trainTargetOutput_labels)))      
   [~, ~, ~, hypoOutput] = fProp_bProp(ffNN, validInput);
   calcs = costFuncAvg_crossEntropy_softmax...
      (hypoOutput, validTargetOutput);
   validCost = sprintf('%.3g', calcs.val)
   validConfidence = sprintf('%.3g%%', ...
      100 * sum(sum(hypoOutput .* validTargetOutput)) ...
      / validNumCases)
   pred = predict(ffNN, validInput);
   trainAccuracy = sprintf('%.3g%%', ...
      100 * mean(double(pred == validTargetOutput_labels)))   
   fprintf('\n');
   
endfunction