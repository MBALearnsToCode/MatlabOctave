function model = ffNN_learnWordReps_HintonNNML...
   (trainNumEpochs = 1, trainRandShuff = false, ...
   Nesterov = false, MacKay = false, bestStop = false,  ...
   plotLearningCurves = true)

   startTime = time;
   
   % HYPERPARAMETERS
   % ---------------
   trainBatchSize = 1e2;
   learningRate = 1e-1;
   momentumRate = 0.9;
   numEmbedNodes = 50;
   numHidNodes = 200;
   initBiasWeightSD = 1e-2;

   % PARAMETERS FOR TRACKING TRAINING PROGRESS
   % -----------------------------------------
   trainCostApproxChunk_everyNumBatches = 1e2;
   validCostCalcInterval_everyNumChunks = 1e1;

   % LOAD DATA
   % ---------
   [trainInput trainTargetOutput ...
      validInput validTargetOutput ...
      testInput testTargetOutput ...
      vocab] = loadData;
   numWords = columns(trainInput);
   vocabSize = length(vocab);
   
   % SET UP NEURAL NET
   % -----------------
   ffNN = class_ffNN(numWords, ...
      {[vocabSize numEmbedNodes] ...
      [(numWords * numEmbedNodes + 1) numHidNodes] ...
      [(numHidNodes + 1) vocabSize]}, ...
      {'embedClassIndices_inRealFeatures' ...
      'logistic' 'softmax'}, false, true, ...
      initBiasWeightSD);

   % TRAIN NEURAL NET
   % ----------------
   if (MacKay)
      regulArgs_list = {{'L2' 'MacKay_empBayes'} [0]};
   else
      regulArgs_list = {{'L2'} [0]};
   endif
   ffNN = train_gradDesc(ffNN, ...
      {trainInput trainTargetOutput ...
      validInput validTargetOutput ...
      testInput testTargetOutput}, vocabSize, ...
      trainNumEpochs, trainBatchSize, trainRandShuff, ...
      trainCostApproxChunk_everyNumBatches, ...
      validCostCalcInterval_everyNumChunks, ...
      learningRate, momentumRate, Nesterov, ...
      regulArgs_list, bestStop, {}, plotLearningCurves);
   endTime = time;
   duration = endTime - startTime;
   fprintf(1, 'Training took %.2f seconds\n', duration);

end